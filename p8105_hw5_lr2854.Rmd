---
title: "HW5"
author: "Lauren Richter"
date: "2021-11-20"
link: "https://www.p8105.com/homework_5.html"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = TRUE, collapse = TRUE)

library(tidyverse)
library(readxl)
```

## Problem 1

```{r import_data, echo = FALSE}
homicide_data = read_csv("data/homicide-data.csv") %>%
  janitor::clean_names("snake")

homicide_df = homicide_data %>%
  mutate(city_state = factor(paste(city,state,sep =", "))) %>%
  group_by(city_state, disposition) %>%
  summarize(city_state, disposition, n_count = n()) %>%
  distinct() %>%
  pivot_wider(names_from = disposition, values_from = n_count) %>%
  janitor::clean_names('snake') %>%
  mutate(
    total_homicides = sum(closed_without_arrest, open_no_arrest, closed_by_arrest, na.rm = TRUE),
    n_unsolved = sum(closed_without_arrest, open_no_arrest, na.rm = TRUE),
    ) %>%
  select(city_state, n_unsolved, total_homicides)

head(homicide_df)

```
The raw data includes `r nrow(homicide_data)` observations of `r ncol(homicide_data)` variables for homicides in the 50 largest US cities (by population in 2012). Each record includes information about the victim, the date of the report, the location of the homicide, and the disposition of the case (whether an arrest was made). The named variables are `r colnames(homicide_data)`. More information about the data is available from the original data source, [here](https://github.com/washingtonpost/data-homicides).

```{r prop_test_bmore, echo = FALSE}

bmore_unsolved = subset(homicide_df, city_state == "Baltimore, MD") %>% pull (n_unsolved)
bmore_total = subset(homicide_df, city_state == "Baltimore, MD") %>% pull(total_homicides)

bmore_prop_test = prop.test(bmore_unsolved,
          bmore_total) %>%
  broom::tidy()

bmore_summary = tibble(
  city_state = "Baltimore, MD",
  n_unsolved = bmore_unsolved,
  total_homicides = bmore_total,
  estimate = pull(bmore_prop_test, estimate),
  conf_low = pull(bmore_prop_test, conf.low),
  conf_high = pull(bmore_prop_test, conf.high)
)

bmore_summary
```

For the city of Baltimore, MD, the estimated proportion is `r round(pull(bmore_prop_test, estimate),3)` (95% confidence interval [`r round(pull(bmore_prop_test, conf.low),3)`, `r round(pull(bmore_prop_test, conf.high),3)`])

Doing this for all of the cities as follows:

```{r city_prop_test}

homicide_df = homicide_df %>% 
  group_by(city_state) %>% 
  mutate(
    test_results = map2(n_unsolved, total_homicides, prop.test),
    tidy_results = map(test_results, broom::tidy)
  ) %>% 
  select(city_state, n_unsolved, total_homicides, tidy_results) %>% 
  unnest(tidy_results) %>% 
  select(city_state, n_unsolved, total_homicides, estimate, conf.low, conf.high) %>% 
  mutate(estimate = round(estimate, 3),
         conf.low = round(conf.low,3),
         conf.high = round(conf.high,3)) %>%
  janitor::clean_names("snake")

homicide_df
```

Cities shown with estimated proportion of unsolved homicides (95% confidence interval). Tulsa, AL appears to be an outlier and is included for completeness.

```{r city_estimates}
homicide_df %>% 
  ungroup() %>%
  mutate(city_state = fct_reorder(city_state, desc(estimate))) %>%
  mutate(state = str_sub(city_state, start = -2, end = -1)) %>%
  ggplot(aes(x = city_state, y = estimate, color = state)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf_low, ymax = conf_high)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

## Problem 2

The original data from the longitudinal study was tidied by combining each individual participant's data into one large dataframe.

```{r long_study}
file_names = c(files = list.files("data/study_data/"))

read_multi_csv = function(csv_list) {
  data_df = tibble(
    subject_id = substr(csv_list, 1, 6), 
    study_arm = substr(csv_list, 1, 3), 
    read_csv(str_c("data/study_data/", csv_list), show_col_types = FALSE))
  return(data_df)
}

study_data = map_dfr(file_names, read_multi_csv) %>% 
  mutate(
    study_arm = ifelse(study_arm == "con", "control", "experimental")
  ) %>%
  select(study_arm, everything())

knitr:::kable(study_data)
```

A spaghetti plot showing observations for each subject over time reveals a trend that the experimental group, but not the control group, sees a rise in the study value over time.

```{r study_trends}
study_data %>% 
  pivot_longer(week_1:week_8, names_to = "week", 
    names_prefix = "week_") %>%
  ggplot(aes(x = week, y = value)) +
  geom_line(aes(group = subject_id, color = study_arm)) + 
  labs(
    title = "Study Measurements over Time", 
    y = "Value",
    x = "Week", 
    color = "Arm"
  ) 
```



## Problem 3

Creating an iris dataset with missing data. The code below will replace 20 random observations with NA values.

```{r missing_iris}
library(tidyverse)
set.seed(10)
iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))
```

The function below takes a variable vector as an argument and replaces the missing values as follows:
- Filling in the missing numeric variables with the mean of the non-missing values.
- Filling in missing character variables with "virginica"

There were `r sum(is.na(iris_with_missing))` missing values in the `iris_with_missing` dataset, of which `r sum(is.na(pull(iris_with_missing, Species)))` were character variables. This corresponds to 20 missing observations (5 variables).

```{r find_iris}
replace_na = function(var_vec) {
  if (is.numeric(var_vec)) {
    var_vec = ifelse(is.na(var_vec), 
                     round(mean(var_vec, na.rm = TRUE), 3), 
                     round(var_vec, 3))
  }
  else if (is.character(var_vec)) {
    var_vec = ifelse(is.na(var_vec), 
                     "virginica", 
                     var_vec)
  }
  return(var_vec)
}

found_iris = map_df(iris_with_missing, replace_na)
```


